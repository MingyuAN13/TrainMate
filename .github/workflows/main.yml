name: CICD Workflow

on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

env:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: ""
  DB_PORT: 5432
  DB_SERVER: db
  DB_NAME: trainmate_db
  DB_USER: trainmate_user
  DB_PASS: pass
  REST_HOST_ADDRESS: rest
  REST_PORT: 5002
  FRONTEND_HOST_ADDRESS: frontend
  FRONTEND_PORT: 3000
  WEBDAV_HOST: http://webdav
  WEBDAV_PORT: 8081
  WEBDAV_TOKEN: Bearer testtoken
  COUCHDB_USER: trainmate
  COUCHDB_SERVER: couch_db
  COUCHDB_NAME: trainmate_db
  COUCHDB_PORT: 5984
  COUCHDB_PASSWORD: pass

jobs:
  lint-python:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.12.3

      - name: Install dependencies
        run: |
          pip install pylint
          pip install -r ./rest_api/requirements.txt

      - name: Run pylint on rest_api
        run: pylint ./rest_api/

      - name: Run pylint on rest_api_tests
        run: pylint ./rest_api_tests

  lint-typescript:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Node.js
        uses: actions/setup-node@v2
        with:
          node-version: 20

      - name: Install dependencies
        run: |
          cd frontend
          npm install

      - name: Run lint
        run: |
          cd frontend
          npm run lint

  # analyze-code:
  #   runs-on: ubuntu-latest
  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v2

  #     - name: Install dependencies
  #       run: |
  #         cd frontend
  #         npm install
  #         cd ..
  #         pip install -r ./rest_api/requirements.txt

  #     - name: Analyze with SonarCloud
  #       uses: SonarSource/sonarcloud-github-action@4006f663ecaf1f8093e8e4abb9227f6041f52216
  #       env:
  #         SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
  #       with:
  #         # Additional arguments for the SonarScanner CLI
  #         args:
  #             -Dsonar.organization=mingyuan13
  #             -Dsonar.projectKey=MingyuAN13_TrainMate
  #             -Dsonar.sources=. 
  #             -Dsonar.login=$SONAR_TOKEN
  #             -Dproject.settings=.ci/sonar-project.properties
  #             -X

  #     # - name: Analyze code with Understand
  #     #   run: |
  #     #     und -verbose analyze -db .ci/understand-settings.und || true
  #     #     und -verbose metrics .ci/understand-settings.und || true
  #     #     und export -format longnoroot -dependencies file csv .ci/dependencies.csv .ci/understand-settings.und

  #     # - name: Upload Understand artifacts
  #     #   uses: actions/upload-artifact@v2
  #     #   with:
  #     #     name: understand-artifacts
  #     #     path: |
  #     #       .ci/understand-settings.csv
  #     #       .ci/dependencies.csv
  #     - name: Fetch SonarCloud Issues
  #       env:
  #         SONAR_PROJECT_KEY: MingyuAN13_TrainMate
  #       run: |
  #         mkdir -p .ci
  #         curl -s -u ${{ secrets.SONAR_TOKEN }}: \
  #         "https://sonarcloud.io/api/measures/component_tree?component=${{ env.SONAR_PROJECT_KEY }}&metricKeys=complexity,ncloc,comment_lines_density,functions&ps=500" \
  #           > .ci/sonar_analysis.json
  #         if [ ! -s .ci/sonar_analysis.json ]; then
  #         echo "Failed to generate sonar_analysis.json"
  #         exit 1
  #         fi
      
  #     - name: Upload Sonar Analysis JSON
  #       uses: actions/upload-artifact@v2
  #       with:
  #         name: sonar-analysis-json
  #         path: .ci/sonar_analysis.json

  #     - name: Download Sonar Analysis Artifact
  #       uses: actions/download-artifact@v2
  #       with:
  #         name: sonar-analysis-json
  #         path: .ci

  #     - name: Convert Sonar JSON to CSV
  #       working-directory: .ci
  #       run: |
  #         python3 generate_csv.py sonar_analysis.json sonar_analysis.csv

  #     - name: Upload CSV as Artifact
  #       uses: actions/upload-artifact@v2
  #       with:
  #         name: sonar-analysis-csv
  #         path: .ci/sonar_analysis.csv
      
  #     - name: Set up OWASP Dependency-Check
  #       run: |
  #         wget https://github.com/jeremylong/DependencyCheck/releases/download/v10.0.3/dependency-check-10.0.3-release.zip
  #         unzip dependency-check-10.0.3-release.zip -d dependency-check
  #         ls dependency-check # List files to confirm correct extraction

  #     - name: Run Dependency-Check
  #       env:
  #         NVD_API_KEY: ${{ secrets.NVD_API_KEY }}
  #       run: dependency-check/dependency-check/bin/dependency-check.sh --project "TrainMate" --scan . --out dependency_graph --format CSV --nvdApiKey $NVD_API_KEY

  #     - name: Upload CSV as Artifact
  #       uses: actions/upload-artifact@v2
  #       with:
  #         name: dependency-csv-b
  #         path:  /home/runner/work/TrainMate/TrainMate/dependency_graph/dependency-check-report.csv  

  #     - name: Parse Dependency-Check CSV
  #       run: |
  #         python3 .ci/convert_csv.py

  #     - name: Upload CSV as Artifact
  #       uses: actions/upload-artifact@v2
  #       with:
  #         name: dependency-csv
  #         path: .ci/parsed_dependency_report.csv

  # analyze-duplication:
  #   runs-on: ubuntu-latest
  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v2

  #     - name: Set up Java
  #       uses: actions/setup-java@v2
  #       with:
  #         java-version: 17
  #         distribution: 'adopt'

  #     - name: Run Simian for code duplication analysis
  #       run: |
  #         java -jar .ci/simian-4.0.0.jar -balanceParentheses -failOnDuplication -ignoreCharacterCase -ignoreCurlyBraces -ignoreIdentifierCase -ignoreModifiers -ignoreStringCase -threshold=6 -formatter="yaml" "./rest_api/*.py" "./frontend/src/*.ts" "./frontend/src/*.tsx"

  # validate-analysis:
  #   runs-on: ubuntu-latest
  #   needs: analyze-code
  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v2

  #     - name: Set up Rust
  #       uses: actions-rust-lang/setup-rust-toolchain@v1

  #     - name: Download Sonar Analysis CSV Artifact
  #       uses: actions/download-artifact@v2
  #       with:
  #         name: sonar-analysis-csv
  #         path: .ci
      
  #     - name: Download Dependency Graph Artifact
  #       uses: actions/download-artifact@v2
  #       with:
  #         name: dependency-csv
  #         path: .ci

  #     - name: List files in .ci directory after CSV generation
  #       run: |
  #         ls -al .ci

  #     - name: Validate analysis
  #       run: |
  #         cd .ci/understand-validator
  #         cargo run --release

  build-frontend:
    runs-on: ubuntu-latest
    services:
      docker:
        image: docker:20.10.7
        options: --privileged
    env:
      IMAGE_TAG: mingyu207/trainmate:frontend
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Write env file
        run: |
          printenv | grep -E 'DB_PORT|DB_SERVER|DB_NAME|DB_USER|DB_PASS|REST_HOST_ADDRESS|REST_PORT|FRONTEND_PORT|FRONTEND_HOST_ADDRESS|WEBDAV_HOST|WEBDAV_PORT|WEBDAV_TOKEN|COUCHDB_USER|COUCHDB_SERVER|COUCHDB_NAME|COUCHDB_PORT|COUCHDB_PASSWORD' > environment/.env.ci

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.CI_REGISTRY_USER }}
          password: ${{ secrets.CI_REGISTRY_PASSWORD }}

      - name: Build and push Docker image
        run: |
          cd frontend
          docker pull $IMAGE_TAG || true
          docker buildx build --load -f Dockerfile.prod -t $IMAGE_TAG --build-arg REST_HOST_ADDRESS=$REST_HOST_ADDRESS --build-arg REST_PORT=$REST_PORT --build-arg NEXT_PUBLIC_FRONT_PORT=$FRONTEND_PORT --build-arg BUILDKIT_INLINE_CACHE=1 .
          docker push $IMAGE_TAG

  build-rest-api:
    runs-on: ubuntu-latest
    services:
      docker:
        image: docker:20.10.7
        options: --privileged
    env:
      IMAGE_TAG: mingyu207/trainmate:rest_api
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.CI_REGISTRY_USER }}
          password: ${{ secrets.CI_REGISTRY_PASSWORD }}

      - name: Build and push Docker image
        run: |
          cd rest_api
          docker pull $IMAGE_TAG || true
          docker buildx build --load -f Dockerfile.prod -t $IMAGE_TAG --build-arg BUILDKIT_INLINE_CACHE=1 --cache-from $IMAGE_TAG .
          docker push $IMAGE_TAG

  build-rest-api-test:
    runs-on: ubuntu-latest
    services:
      docker:
        image: docker:20.10.7
        options: --privileged
    env:
      IMAGE_TAG: mingyu207/trainmate:rest_api-test
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.CI_REGISTRY_USER }}
          password: ${{ secrets.CI_REGISTRY_PASSWORD }}

      - name: Build and push Docker image
        run: |
          docker pull $IMAGE_TAG || true
          docker buildx build --load -f rest_api_tests/Dockerfile -t $IMAGE_TAG --build-arg BUILDKIT_INLINE_CACHE=1 --cache-from $IMAGE_TAG .
          docker push $IMAGE_TAG

  build-cypress:
    runs-on: ubuntu-latest
    services:
      docker:
        image: docker:20.10.7
        options: --privileged
    env:
      IMAGE_TAG: mingyu207/trainmate:cypress
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.CI_REGISTRY_USER }}
          password: ${{ secrets.CI_REGISTRY_PASSWORD }}

      - name: Build and push Docker image
        run: |
          cd cypress
          docker pull $IMAGE_TAG || true
          docker buildx build --load -t $IMAGE_TAG --cache-from $IMAGE_TAG .
          docker push $IMAGE_TAG

  test-python:
    runs-on: ubuntu-latest
    services:
      docker:
        image: docker:20.10.7
        options: --privileged
    env:
      IMAGE_TAG: mingyu207/trainmate:latest
    needs: build-rest-api-test
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Write env file
        run: |
          printenv | grep -E 'DB_PORT|DB_SERVER|DB_NAME|DB_USER|DB_PASS|REST_HOST_ADDRESS|REST_PORT|FRONTEND_PORT|FRONTEND_HOST_ADDRESS|WEBDAV_HOST|WEBDAV_PORT|WEBDAV_TOKEN|COUCHDB_USER|COUCHDB_SERVER|COUCHDB_NAME|COUCHDB_PORT|COUCHDB_PASSWORD' > environment/.env.ci

      - name: Log in to Docker Hub
        run: echo "${{ secrets.CI_REGISTRY_PASSWORD }}" | docker login ${{ secrets.CI_REGISTRY }}

  deployment:
    runs-on: ubuntu-latest
    needs: [build-frontend, build-rest-api, build-rest-api-test, build-cypress]
    steps: 
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Install Kind
        uses: engineerd/setup-kind@v0.5.0
        with:
          version: v0.17.0

      - name: Create Kind Cluster
        run: |
          kind create cluster --name cluster --config=../.kubernetes/config.yaml

      - name: Set up Kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: latest
      
      # - name: Test Docker pull image
      #   run: |
      #     docker pull mingyu207/trainmate:frontend
      #     docker pull mingyu207/trainmate:rest_api
      #     docker pull mingyu207/trainmate:rest_api-test
      #     docker pull mingyu207/trainmate:cypress

      - name: Apply Metrics Server
        run: |
          kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
          kubectl patch deployment metrics-server -n kube-system --patch '{"spec": {"template": {"spec": {"containers": [{"name": "metrics-server","args": ["--kubelet-insecure-tls", "--cert-dir=/tmp"]}]}}}}'

      - name: Wait for Metrics Server to be Ready
        run: |
          kubectl wait --for=condition=available --timeout=300s deployment/metrics-server -n kube-system

      - name: Check Metrics Server Logs
        run: |
          kubectl logs -l k8s-app=metrics-server -n kube-system || echo "No logs available yet."

      - name: Check Events in kube-system Namespace
        run: |
          kubectl get events --sort-by='.lastTimestamp' -n kube-system

      - name: Deploy to Kubernetes
        run: |
          cd kubernetes
          kubectl apply -f deployment.yaml
          kubectl apply -f service.yaml
      
      # - name: Describe Node
      #   run: |
      #     kubectl describe node cluster-control-plane

      # - name: Check Pod Status and Events
      #   run: |
      #     # Get the first pod name with the label app=trainmate
      #     POD_NAME=$(kubectl get pods -l app=trainmate -o jsonpath='{.items[0].metadata.name}')
      #     echo "Pod Name: $POD_NAME"
          
      #     # Describe the pod to check events and status
      #     kubectl describe pod $POD_NAME
          
      #     # Check for Image Pulling Issues
      #     if kubectl describe pod $POD_NAME | grep -q 'ErrImagePull\|ImagePullBackOff'; then
      #       echo "Image pull issue detected!"
            
      #       # Fetch logs from all containers in the pod to understand the issue better
      #       kubectl logs $POD_NAME --all-containers=true
            
      #       exit 1
      #     fi
      
      # - name: Check Volume Mount Issues
      #   run: |
      #     POD_NAME=$(kubectl get pods -l app=trainmate -o jsonpath='{.items[0].metadata.name}')
      #     kubectl describe pod $POD_NAME | grep -i 'MountVolume.SetUp failed' && \
      #     (echo "Volume mount issue detected!" && exit 1) || \
      #     echo "No volume mount issues detected."

      # - name: Check Node Resource Availability
      #   run: |
      #     kubectl describe node cluster-control-plane
      #     kubectl top node cluster-control-plane || echo "Metrics server is not available."

      # - name: Check Image Pulling Status
      #   run: |
      #     POD_NAME=$(kubectl get pods -l app=trainmate -o jsonpath='{.items[0].metadata.name}')
      #     kubectl describe pod $POD_NAME | grep -i 'pull' || echo "No image pull issues detected."

      # - name: Get Detailed Events
      #   run: |
      #     kubectl get events --sort-by='.lastTimestamp' -n default

      # - name: Check Container Logs (if available)
      #   run: |
      #     POD_NAME=$(kubectl get pods -l app=trainmate -o jsonpath='{.items[0].metadata.name}')
      #     CONTAINERS=$(kubectl get pod $POD_NAME -o jsonpath='{.spec.containers[*].name}')
      #     for CONTAINER in $CONTAINERS; do
      #       echo "Fetching logs for container: $CONTAINER in pod: $POD_NAME"
      #       kubectl logs $POD_NAME -c $CONTAINER || echo "No logs available for container: $CONTAINER"
      #     done

      # - name: Deploy a DNS Test Pod
      #   run: |
      #     kubectl run dns-test --image=busybox --restart=Never -- sleep 3600

      # - name: Verify DNS Resolution
      #   run: |
      #     kubectl exec dns-test -- nslookup kubernetes.default || \
      #     (echo "DNS resolution failed!" && exit 1)
      #     kubectl exec dns-test -- ping -c 4 kubernetes.default || \
      #     (echo "Ping to kubernetes.default failed!" && exit 1)

      # - name: Check CoreDNS Logs
      #   run: |
      #     COREDNS_PODS=$(kubectl get pods -n kube-system -l k8s-app=kube-dns -o jsonpath='{.items[*].metadata.name}')
      #     for POD in $COREDNS_PODS; do
      #       echo "Checking logs for CoreDNS pod: $POD"
      #       kubectl logs -n kube-system $POD || \
      #       (echo "Failed to get logs for CoreDNS pod $POD!" && exit 1)
      #     done

      # - name: Cleanup DNS Test Pod
      #   run: |
      #     kubectl delete pod dns-test || echo "Failed to delete test pod dns-test"

      - name: Wait for Application Pods to be Ready
        run: |
          kubectl wait --for=condition=ready pod -l app=trainmate --timeout=600s

      - name: Check Application Logs
        run: |
          POD_NAME=$(kubectl get pods -l app=trainmate -o jsonpath='{.items[0].metadata.name}')
          kubectl logs $POD_NAME || echo "No logs available yet."

      - name: Describe Application Pods
        run: |
          POD_NAME=$(kubectl get pods -l app=trainmate -o jsonpath='{.items[0].metadata.name}')
          kubectl describe pod $POD_NAME

      - name: Check Application Events
        run: |
          kubectl get events --sort-by='.lastTimestamp' -n default

      # - name: Check pod status and fetch logs
      #   run: |
      #     MAX_RETRIES=3
      #     RETRY_COUNT=0

      #     # Fetch all pod names with the label "app=trainmate"
      #     PODS=$(kubectl get pods -l app=trainmate -o jsonpath='{.items[*].metadata.name}')

      #     # Check if there are any pods to process
      #     if [ -z "$PODS" ]; then
      #       echo "No pods found with label app=trainmate. Exiting."
      #       exit 1
      #     fi

      #     for POD in $PODS; do
      #       echo "Checking initial status for pod: $POD"
            
      #       # Get the current phase of the pod
      #       POD_PHASE=$(kubectl get pod $POD -o jsonpath='{.status.phase}')
      #       echo "Initial phase of pod $POD is $POD_PHASE."

      #       if [ "$POD_PHASE" != "Running" ]; then
      #         echo "Pod $POD is not in Running phase, it's in $POD_PHASE. Checking details..."

      #         # Describe the pod to get more details
      #         kubectl describe pod $POD

      #         # Check if the pod is in a pending or container creating state
      #         if [ "$POD_PHASE" == "Pending" ] || [ "$POD_PHASE" == "ContainerCreating" ]; then
      #           echo "Pod $POD is $POD_PHASE. Waiting for it to become ready..."
      #           while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
      #             if kubectl wait --for=condition=ready pod/$POD --timeout=60s; then
      #               echo "Pod $POD is ready."
      #               break
      #             else
      #               echo "Pod $POD is not ready yet. Retrying... ($RETRY_COUNT/$MAX_RETRIES)"
      #               ((RETRY_COUNT++))
      #               sleep 10
      #             fi
      #           done
      #         fi

      #         if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
      #           echo "Pod $POD did not become ready after $MAX_RETRIES attempts. Exiting."
      #           kubectl describe pod $POD
      #           kubectl get pod $POD -o wide
      #           exit 1
      #         fi
      #       else
      #         echo "Pod $POD is already in Running phase."
      #       fi

      #       # Reset retry counter for next pod
      #       RETRY_COUNT=0

      #       # Fetch logs for each container in the pod
      #       for CONTAINER in frontend rest-api rest-api-test cypress; do
      #         echo "Fetching logs for container: $CONTAINER in pod: $POD"
      #         kubectl logs $POD -c $CONTAINER || echo "No logs available for container: $CONTAINER in pod: $POD"
      #       done
      #     done

      - name: Verify Deployment
        run: |
          kubectl get pods --selector=app=trainmate --show-labels
          kubectl get pv
          kubectl get pvc
          


